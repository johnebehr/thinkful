{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms Basics\n",
    "An _algorithm_ is a set of instructions for a computer.  Algorithmic efficiency and complexity matter in part because Data Science often deals with large amounts of data.  The more data you have the less tolerance for inefficiency a computer has, and it starts to matter how much work it takes for a computer to work with large scale data. \n",
    "Different kinds of algorithms scale in different ways.  An algorithm that compares number for example: <br />\n",
    "``` python\n",
    "for i in numbers:   \n",
    "    print(i>4)\n",
    "```\n",
    "scales linearly and is said to have _linear complexity_.  Each additional element in `numbers` adds an additional step to the algorithm.  If you add complexity say: \n",
    "``` python\n",
    "for i in numbers:\n",
    "    for j in numbers:\n",
    "        print(i>j)\n",
    "```\n",
    "The algorithm no longer scales linearly.  If there is one element in `numbers` the print statement runs once.  If there are two elements in `numbers` it runs four times.  If there are three elements it runs nine times.  The more complex algorithm scales according to the square of the length of `numbers`.  The algorithm has _quadratic complexity_.  Different algorithms see the number of steps they take grow at different rates and in different functional forms.\n",
    "## Big O Notation\n",
    "Big O Notation is the way to describe the scaling rate.  For each algorithm you can use Big O Notation to describe a limiting functional form.  As the number of elements in the algorithm’s input grows, the notation shows the lower bound of performance.  So, something that is O_(n) will be at worst n steps.  O_(n^2) is at worst n^2 steps.  For something that is O_(n), the algorithm will run in n steps or less.\n",
    "When thinking about Big O Notation, you only care about the things that grow most quickly as the dataset scales.  The key is that when using Big O Notation to refer to an algorithm’s complexity, you’re talking about how efficiently the algorithm scales with additional data.  Efficiency often matters because it sets an upper bound on the size of the dataset you can reasonably work with.\n",
    "## References:\n",
    "Pseudocode: https://medium.com/@abdulfataiaka/pseudocode-6f024b0a2a6 <br />\n",
    "A Gentle Introduction to Algorithm Complexity Analysis: http://discrete.gr/complexity/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}