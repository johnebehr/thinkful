{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitbasecondacff6a9491553481ea55fb54c6034a878",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll continue working with the house prices data. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Reimplement your model from the previous checkpoint.\n",
    "* Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do **k-fold cross-validation** to choose the best hyperparameter values for your models. Scikit-learn has RidgeCV, LassoCV, and ElasticNetCV that you can utilize to do this. Which model is the best? Why?\n",
    "\n",
    "This is not a graded checkpoint, but you should discuss your solution with your mentor. After you've submitted your work, take a moment to compare your solution to [this example solution](https://github.com/Thinkful-Ed/machine-learning-regression-problems/blob/master/notebooks/7.solution_overfitting_and_regularization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm # Not used in this assignemnt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from statsmodels.tools.eval_measures import mse, rmse \n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy.engine.url import URL \n",
    "\n",
    "from sklearn.linear_model import Ridge # New for this assignment\n",
    "from sklearn.linear_model import Lasso # New for this assignment\n",
    "from sklearn.linear_model import ElasticNet # New for this assignment\n",
    "\n",
    "from sklearn.model_selection import cross_val_score # For cross-validation\n",
    "from sklearn.model_selection import KFold # For cross-validation\n",
    "\n",
    "pd.options.display.float_format = \"{:3f}\".format\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "kagle = dict(\n",
    "    drivername = \"postgresql\",\n",
    "    username = \"dsbc_student\",\n",
    "    password = \"7*.8G9QH21\",\n",
    "    host = \"142.93.121.174\",\n",
    "    port = \"5432\",\n",
    "    database = \"houseprices\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model,X_train, X_test, y_train, y_test, y_preds_train, y_preds_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    mae_score = mean_absolute_error(y_test, y_preds_test)\n",
    "    mse_score = mse(y_test, y_preds_test)\n",
    "    rmse_score = rmse(y_test, y_preds_test)\n",
    "    mape_score = np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100\n",
    "\n",
    "    return [train_score, test_score, mae_score, mse_score, rmse_score, mape_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(train_score, test_score, mae_score, mse_score, rmse_score, mape_score):\n",
    "    print(f\"R-squared of the model in the training set is: {train_score:,.4f}\")\n",
    "    print(\"\\n\", 30*\"-\", \"Test set statistics\", 30*\"-\", \"\\n\")\n",
    "    print(f\"R-squared of the model in the test set is: {test_score:,.4f}\")\n",
    "    print(f\"Mean absolute error of the prediction is: {mae_score:,.4f}\")\n",
    "    print(f\"Mean squared error of the prediction is: {mse_score:,.4f}\")\n",
    "    print(f\"Root mean squared error of the prediction is: {rmse_score:,.4f}\")\n",
    "    print(f\"Mean absolute percentage error of the prediction is: {mape_score:,.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-01-09 12:43:59,189 INFO sqlalchemy.engine.base.Engine select version()\n2020-01-09 12:43:59,190 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 12:43:59,284 INFO sqlalchemy.engine.base.Engine select current_schema()\n2020-01-09 12:43:59,285 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 12:43:59,381 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n2020-01-09 12:43:59,382 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 12:43:59,431 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n2020-01-09 12:43:59,432 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 12:43:59,479 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n2020-01-09 12:43:59,480 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 12:43:59,578 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n2020-01-09 12:43:59,578 INFO sqlalchemy.engine.base.Engine {'name': 'SELECT * FROM houseprices'}\n2020-01-09 12:43:59,724 INFO sqlalchemy.engine.base.Engine SELECT * FROM houseprices\n2020-01-09 12:43:59,726 INFO sqlalchemy.engine.base.Engine {}\n"
    }
   ],
   "source": [
    "# Load the data from the medicalcosts database\n",
    "engine=create_engine(URL(**kagle), echo=True)\n",
    "\n",
    "houses_raw = pd.read_sql(\"SELECT * FROM houseprices\", con=engine)\n",
    "\n",
    "# No need for an open connection, please close\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the raw data to work on\n",
    "houses_working = houses_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_winsorized = houses_working[[\"neighborhood\",\"overallqual\",\"lotarea\",\n",
    "                                    \"totalbsmtsf\",\"firstflrsf\",\"grlivarea\",\n",
    "                                    \"totrmsabvgrd\",\"garagecars\",\"garagearea\",\"saleprice\"]]\n",
    "\n",
    "# Winsorized values were derrived during EDA\n",
    "winsorize_vals = dict(\n",
    "    lotarea=(0.10,0.05),\n",
    "    totalbsmtsf=(0.10,0.05),\n",
    "    firstflrsf=(0.0,0.1),\n",
    "    grlivarea=(0.0,0.1),\n",
    "    totrmsabvgrd=(0.0,0.1),\n",
    "    garagecars=(0.0,0.1),\n",
    "    garagearea=(0.0,0.1),\n",
    "    saleprice=(0.0,0.1)\n",
    ")\n",
    "\n",
    "# Add a column for each of the winsorized values\n",
    "for i, (k,v) in enumerate(winsorize_vals.items()):\n",
    "    houses_winsorized[f\"{k}_winsorized\"] = winsorize(houses_winsorized[k], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of dummies for the neighborhood variable, prefix the dummies with \"neighborhood\"\n",
    "houses_winsorized = pd.concat([houses_winsorized, pd.get_dummies(houses_winsorized[\"neighborhood\"], prefix=\"neighborhood\",drop_first=True)], axis=1)\n",
    "\n",
    "# Create a set of dumies for the overallqual variable, previs the dummies with \"overallqual\"\n",
    "houses_winsorized = pd.concat([houses_winsorized, pd.get_dummies(houses_winsorized[\"overallqual\"], prefix=\"overallqual\",drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an interaction between garagecars and garagearea\n",
    "houses_winsorized[\"garagecars_garagearea\"] = houses_winsorized[\"garagecars\"] * houses_winsorized[\"garagearea\"]\n",
    "\n",
    "# Get a list of column names to be used for feature consideration\n",
    "feature_names = houses_winsorized.iloc[:,2:].columns.to_list()\n",
    "\n",
    "# Pop saleprice from the list of feature_names\n",
    "feature_names.pop(15)\n",
    "\n",
    "# Get the final list of feature columns for the model\n",
    "feature_names = feature_names[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "With 20.0% Holdout: 85.235%\nTesting on Sample: 86.925%\nAccuracy: 0.86% (+/- 0.07) Mode: 0.759648%\nR-squared of the model in the training set is: 0.8711\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: 0.8619\nMean absolute error of the prediction is: 16,640.4101\nMean squared error of the prediction is: 487,224,950.4771\nRoot mean squared error of the prediction is: 22,073.1726\nMean absolute percentage error of the prediction is: 10.7951\n"
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = houses_winsorized[\"saleprice_winsorized\"]\n",
    "\n",
    "# X is the feature set\n",
    "X = houses_winsorized[feature_names]\n",
    "\n",
    "test_size = 0.20\n",
    "random_state = 465\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "# Fit an OLS model using sklearn\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "print(f\"With {test_size*100}% Holdout: {lrm.fit(X_train, y_train).score(X_test, y_test)*100:.3f}%\")\n",
    "print(f\"Testing on Sample: {lrm.fit(X,Y).score(X,Y)*100:.3f}%\")\n",
    "\n",
    "cv_scores = cross_val_score(lrm,X,Y,cv=28)\n",
    "print(f\"Accuracy: {cv_scores.mean():.2f}% (+/- {cv_scores.std()*2:.2f}) Mode: {stats.mode(cv_scores)[0][0]:2f}%\")\n",
    "\n",
    "# Make some predictions\n",
    "m1_y_preds_train = lrm.predict(X_train)\n",
    "m1_y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "# Get the model_01 scores (m1)\n",
    "m1_scores = get_test_scores(lrm, X_train, X_test, y_train, y_test, m1_y_preds_train, m1_y_preds_test)\n",
    "m1_scores.insert(0,\"model_01\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m1_scores[1], m1_scores[2], m1_scores[3], m1_scores[4], m1_scores[5], m1_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# Now, a Ridge regression\n",
    "ridgeregr = Ridge(alpha=10**37)\n",
    "ridgeregr.fit(X_train, y_train)\n",
    "\n",
    "# Make some predictions\n",
    "m2_y_preds_train = ridgeregr.predict(X_train)\n",
    "m2_y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "# Get the model_02 scores (m2)\n",
    "m2_scores = get_test_scores(ridgeregr, X_train, X_test, y_train, y_test, m2_y_preds_train, m2_y_preds_test)\n",
    "m2_scores.insert(0,\"model_02\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m2_scores[1], m2_scores[2], m2_scores[3], m2_scores[4], m2_scores[5], m2_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# This time a Lasso regression\n",
    "lassoregr = Lasso(alpha=10**20.5)\n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions here\n",
    "m3_y_preds_train = lassoregr.predict(X_train)\n",
    "m3_y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "# Get the model_03 scores (m3)\n",
    "m3_scores = get_test_scores(ridgeregr, X_train, X_test, y_train, y_test, m3_y_preds_train, m3_y_preds_test)\n",
    "m3_scores.insert(0,\"model_03\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m3_scores[1], m3_scores[2], m3_scores[3], m3_scores[4], m3_scores[5], m3_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# Finally, an ElasticNet regression\n",
    "elasticregr = ElasticNet(alpha=10**21, l1_ratio=0.5)\n",
    "elasticregr.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions here\n",
    "m4_y_preds_train = elasticregr.predict(X_train)\n",
    "m4_y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "# Get the model_04 scores (m3)\n",
    "m4_scores = get_test_scores(elasticregr, X_train, X_test, y_train, y_test, m4_y_preds_train, m4_y_preds_test)\n",
    "m4_scores.insert(0,\"model_04\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m4_scores[1], m4_scores[2], m4_scores[3], m4_scores[4], m4_scores[5], m4_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe to compare the results\n",
    "comparison_df = pd.DataFrame([m1_scores,m2_scores,m3_scores,m4_scores], \n",
    "    columns=[\"Model\",\"Train_Score\",\"Test_Score\",\"MAE\",\"MSE\",\"RMSE\",\"MAPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Train_Score</th>\n      <th>Test_Score</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>model_01</td>\n      <td>0.871079</td>\n      <td>0.861922</td>\n      <td>16640.410072</td>\n      <td>487224950.477143</td>\n      <td>22073.172642</td>\n      <td>10.795143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>model_02</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>model_03</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>model_04</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      Model  Train_Score  Test_Score          MAE               MSE  \\\n0  model_01     0.871079    0.861922 16640.410072  487224950.477143   \n1  model_02     0.000000   -0.003349 49645.317297 3540445067.421752   \n2  model_03     0.000000   -0.003349 49645.317297 3540445067.421752   \n3  model_04     0.000000   -0.003349 49645.317297 3540445067.421752   \n\n          RMSE      MAPE  \n0 22073.172642 10.795143  \n1 59501.639199 33.638882  \n2 59501.639199 33.638882  \n3 59501.639199 33.638882  "
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with different holdout gorups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}