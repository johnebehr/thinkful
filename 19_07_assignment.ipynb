{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitbasecondacff6a9491553481ea55fb54c6034a878",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll continue working with the house prices data. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Reimplement your model from the previous checkpoint.\n",
    "* Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do **k-fold cross-validation** to choose the best hyperparameter values for your models. Scikit-learn has RidgeCV, LassoCV, and ElasticNetCV that you can utilize to do this. Which model is the best? Why?\n",
    "\n",
    "This is not a graded checkpoint, but you should discuss your solution with your mentor. After you've submitted your work, take a moment to compare your solution to [this example solution](https://github.com/Thinkful-Ed/machine-learning-regression-problems/blob/master/notebooks/7.solution_overfitting_and_regularization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm # Not used in this assignemnt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statsmodels.tools.eval_measures import mse, rmse \n",
    "from sqlalchemy import create_engine \n",
    "from sqlalchemy.engine.url import URL \n",
    "\n",
    "from sklearn.linear_model import Ridge # New for this assignment\n",
    "from sklearn.linear_model import Lasso # New for this assignment\n",
    "from sklearn.linear_model import ElasticNet # New for this assignment\n",
    "\n",
    "from sklearn.model_selection import cross_val_score # For cross-validation\n",
    "from sklearn.model_selection import KFold # For cross-validation\n",
    "\n",
    "# pd.options.display.float_format = \"{:3f}\".format\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "kagle = dict(\n",
    "    drivername = \"postgresql\",\n",
    "    username = \"dsbc_student\",\n",
    "    password = \"7*.8G9QH21\",\n",
    "    host = \"142.93.121.174\",\n",
    "    port = \"5432\",\n",
    "    database = \"houseprices\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model,X_train, X_test, y_train, y_test, y_preds_train, y_preds_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    mae_score = mean_absolute_error(y_test, y_preds_test)\n",
    "    mse_score = mse(y_test, y_preds_test)\n",
    "    rmse_score = rmse(y_test, y_preds_test)\n",
    "    mape_score = np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100\n",
    "\n",
    "    return [train_score, test_score, mae_score, mse_score, rmse_score, mape_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(train_score, test_score, mae_score, mse_score, rmse_score, mape_score):\n",
    "    print(f\"R-squared of the model in the training set is: {train_score:,.4f}\")\n",
    "    print(\"\\n\", 30*\"-\", \"Test set statistics\", 30*\"-\", \"\\n\")\n",
    "    print(f\"R-squared of the model in the test set is: {test_score:,.4f}\")\n",
    "    print(f\"Mean absolute error of the prediction is: {mae_score:,.4f}\")\n",
    "    print(f\"Mean squared error of the prediction is: {mse_score:,.4f}\")\n",
    "    print(f\"Root mean squared error of the prediction is: {rmse_score:,.4f}\")\n",
    "    print(f\"Mean absolute percentage error of the prediction is: {mape_score:,.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-01-09 17:13:32,224 INFO sqlalchemy.engine.base.Engine select version()\n2020-01-09 17:13:32,225 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 17:13:32,334 INFO sqlalchemy.engine.base.Engine select current_schema()\n2020-01-09 17:13:32,335 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 17:13:32,433 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n2020-01-09 17:13:32,435 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 17:13:32,488 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n2020-01-09 17:13:32,488 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 17:13:32,540 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n2020-01-09 17:13:32,541 INFO sqlalchemy.engine.base.Engine {}\n2020-01-09 17:13:32,642 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n2020-01-09 17:13:32,644 INFO sqlalchemy.engine.base.Engine {'name': 'SELECT * FROM houseprices'}\n2020-01-09 17:13:32,793 INFO sqlalchemy.engine.base.Engine SELECT * FROM houseprices\n2020-01-09 17:13:32,794 INFO sqlalchemy.engine.base.Engine {}\n"
    }
   ],
   "source": [
    "# Load the data from the medicalcosts database\n",
    "engine=create_engine(URL(**kagle), echo=True)\n",
    "\n",
    "houses_raw = pd.read_sql(\"SELECT * FROM houseprices\", con=engine)\n",
    "\n",
    "# No need for an open connection, please close\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the raw data to work on\n",
    "houses_working = houses_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_winsorized = houses_working[[\"neighborhood\",\"overallqual\",\"lotarea\",\n",
    "                                    \"totalbsmtsf\",\"firstflrsf\",\"grlivarea\",\n",
    "                                    \"totrmsabvgrd\",\"garagecars\",\"garagearea\",\"saleprice\"]]\n",
    "\n",
    "# Winsorized values were derrived during EDA\n",
    "winsorize_vals = dict(\n",
    "    lotarea=(0.10,0.05),\n",
    "    totalbsmtsf=(0.10,0.05),\n",
    "    firstflrsf=(0.0,0.1),\n",
    "    grlivarea=(0.0,0.1),\n",
    "    totrmsabvgrd=(0.0,0.1),\n",
    "    garagecars=(0.0,0.1),\n",
    "    garagearea=(0.0,0.1),\n",
    "    saleprice=(0.0,0.1)\n",
    ")\n",
    "\n",
    "# Add a column for each of the winsorized values\n",
    "for i, (k,v) in enumerate(winsorize_vals.items()):\n",
    "    houses_winsorized[f\"{k}_winsorized\"] = winsorize(houses_winsorized[k], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of dummies for the neighborhood variable, prefix the dummies with \"neighborhood\"\n",
    "houses_winsorized = pd.concat([houses_winsorized, pd.get_dummies(houses_winsorized[\"neighborhood\"], prefix=\"neighborhood\",drop_first=True)], axis=1)\n",
    "\n",
    "# Create a set of dumies for the overallqual variable, previs the dummies with \"overallqual\"\n",
    "houses_winsorized = pd.concat([houses_winsorized, pd.get_dummies(houses_winsorized[\"overallqual\"], prefix=\"overallqual\",drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an interaction between garagecars and garagearea\n",
    "houses_winsorized[\"garagecars_garagearea\"] = houses_winsorized[\"garagecars\"] * houses_winsorized[\"garagearea\"]\n",
    "\n",
    "# Get a list of column names to be used for feature consideration\n",
    "feature_names = houses_winsorized.iloc[:,2:].columns.to_list()\n",
    "\n",
    "# Pop saleprice from the list of feature_names\n",
    "feature_names.pop(15)\n",
    "\n",
    "# Get the final list of feature columns for the model\n",
    "feature_names = feature_names[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'int' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1253\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-38d3256c683b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Create a Confusion Matrix to repor on model training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     confusion_matrix = dict(\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mfalse_positives\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mtarget_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mfalse_negatives\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0my_pred_correct_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;31m#   integer dtypes.  Otherwise these are boolean ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0mfiller\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_int\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_self_int_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_other_int_dtype\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfill_bool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0movalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m         \u001b[0munfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfilled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1260\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1262\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_binop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1263\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m                 \u001b[1;31m# let null fall thru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'int' and 'float'"
     ]
    }
   ],
   "source": [
    "X  = houses_winsorized[feature_names]\n",
    "y = houses_winsorized[\"saleprice\"]\n",
    "\n",
    "# lrm = LinearRegression()\n",
    "# cross_val_score(lrm,X,y, cv=10)\n",
    "# Set the number of folds (training and test samples)\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Train and test using KFolds\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # print(f\"TRAIN: {train_index} | TEST: {test_index}\")\n",
    "    # i+1 # increment the counter by 1 for human readability\n",
    "\n",
    "    # Create the train samples from the fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "\n",
    "    # Create the test samples from the fold\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Locate the appropriate rows in the garget series\n",
    "    target_ref = y.iloc[train_index]\n",
    "\n",
    "    # Train the model using the train and test data\n",
    "    lrm = LinearRegression()\n",
    "    y_pred = lrm.fit(X_train, y_train).predict(X_train)\n",
    "\n",
    "    # c_mat = confusion_matrix(target,y_pred)\n",
    "\n",
    "    # Create a Confusion Matrix to repor on model training\n",
    "    confusion_matrix = dict(\n",
    "        false_positives=((~target_ref)&(y_pred)).sum(),\n",
    "        false_negatives=((target_ref)&(~y_pred)).sum(),\n",
    "        y_pred_correct_pos=((target_ref)&(y_pred)).sum(),\n",
    "        y_pred_correct_neg=((~target_ref)&(~y_pred)).sum(),\n",
    "        target_pos=(target_ref).sum(),\n",
    "        target_neg=(~target_ref).sum(),\n",
    "        sensitivity=(((target_ref)&(y_pred)).sum()/(target_ref).sum())*100,     \n",
    "        specificity=(((~target_ref)&(~y_pred)).sum()/(~target_ref).sum())*100, \n",
    "        total_errors=(target_ref != y_pred).sum()\n",
    "    )\n",
    "\n",
    "    # Generate a report of model training\n",
    "    print(f\"\"\"Fold {i}:\n",
    "Total Errors: {confusion_matrix[\"total_errors\"]}, False Negatives: {confusion_matrix[\"false_negatives\"]}, False Positives: {confusion_matrix[\"false_positives\"]}, Sensitivity: {confusion_matrix[\"sensitivity\"]:,.4f}% Specificity: {confusion_matrix[\"specificity\"]:,.4f}%\n",
    "Testing on Sample: {bnb.fit(X_test, y_test).score(X_test, y_test)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "With 20.0% Holdout: 85.235%\nTesting on Sample: 86.925%\nAccuracy: 0.86% (+/- 0.07) Mode: 0.759648%\nR-squared of the model in the training set is: 0.8711\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: 0.8619\nMean absolute error of the prediction is: 16,640.4101\nMean squared error of the prediction is: 487,224,950.4771\nRoot mean squared error of the prediction is: 22,073.1726\nMean absolute percentage error of the prediction is: 10.7951\n"
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = houses_winsorized[\"saleprice_winsorized\"]\n",
    "\n",
    "# X is the feature set\n",
    "X = houses_winsorized[feature_names]\n",
    "\n",
    "# Set a basis for the size of the holdout group (corss-validation)\n",
    "test_size = 0.20\n",
    "# Set the amount of randomness in in the sampling\n",
    "random_state = 465\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "# Fit an OLS model using sklearn\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "# Cross validate and print the scores\n",
    "print(f\"With {test_size*100}% Holdout: {lrm.fit(X_train, y_train).score(X_test, y_test)*100:.3f}%\")\n",
    "print(f\"Testing on Sample: {lrm.fit(X,Y).score(X,Y)*100:.3f}%\")\n",
    "\n",
    "cv_scores = cross_val_score(lrm,X,Y,cv=28)\n",
    "print(f\"Accuracy: {cv_scores.mean():.2f}% (+/- {cv_scores.std()*2:.2f}) Mode: {stats.mode(cv_scores)[0][0]:2f}%\")\n",
    "\n",
    "# Set the number of folds (training and test samples)\n",
    "# kf = KFold(n_splits=5)\n",
    "\n",
    "# Train and test using KFolds\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X))\n",
    "\n",
    "# Make some predictions\n",
    "m1_y_preds_train = lrm.predict(X_train)\n",
    "m1_y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "# Get the model_01 scores (m1)\n",
    "m1_scores = get_test_scores(lrm, X_train, X_test, y_train, y_test, m1_y_preds_train, m1_y_preds_test)\n",
    "m1_scores.insert(0,\"model_01\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m1_scores[1], m1_scores[2], m1_scores[3], m1_scores[4], m1_scores[5], m1_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# Now, a Ridge regression\n",
    "ridgeregr = Ridge(alpha=10**37)\n",
    "ridgeregr.fit(X_train, y_train)\n",
    "\n",
    "# Make some predictions\n",
    "m2_y_preds_train = ridgeregr.predict(X_train)\n",
    "m2_y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "# Get the model_02 scores (m2)\n",
    "m2_scores = get_test_scores(ridgeregr, X_train, X_test, y_train, y_test, m2_y_preds_train, m2_y_preds_test)\n",
    "m2_scores.insert(0,\"model_02\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m2_scores[1], m2_scores[2], m2_scores[3], m2_scores[4], m2_scores[5], m2_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# This time a Lasso regression\n",
    "lassoregr = Lasso(alpha=10**20.5)\n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions here\n",
    "m3_y_preds_train = lassoregr.predict(X_train)\n",
    "m3_y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "# Get the model_03 scores (m3)\n",
    "m3_scores = get_test_scores(ridgeregr, X_train, X_test, y_train, y_test, m3_y_preds_train, m3_y_preds_test)\n",
    "m3_scores.insert(0,\"model_03\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m3_scores[1], m3_scores[2], m3_scores[3], m3_scores[4], m3_scores[5], m3_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "R-squared of the model in the training set is: 0.0000\n\n ------------------------------ Test set statistics ------------------------------ \n\nR-squared of the model in the test set is: -0.0033\nMean absolute error of the prediction is: 49,645.3173\nMean squared error of the prediction is: 3,540,445,067.4218\nRoot mean squared error of the prediction is: 59,501.6392\nMean absolute percentage error of the prediction is: 33.6389\n"
    }
   ],
   "source": [
    "# Finally, an ElasticNet regression\n",
    "elasticregr = ElasticNet(alpha=10**21, l1_ratio=0.5)\n",
    "elasticregr.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions here\n",
    "m4_y_preds_train = elasticregr.predict(X_train)\n",
    "m4_y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "# Get the model_04 scores (m3)\n",
    "m4_scores = get_test_scores(elasticregr, X_train, X_test, y_train, y_test, m4_y_preds_train, m4_y_preds_test)\n",
    "m4_scores.insert(0,\"model_04\")\n",
    "\n",
    "# Print the results\n",
    "print_stats(m4_scores[1], m4_scores[2], m4_scores[3], m4_scores[4], m4_scores[5], m4_scores[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe to compare the results\n",
    "comparison_df = pd.DataFrame([m1_scores,m2_scores,m3_scores,m4_scores], \n",
    "    columns=[\"Model\",\"Train_Score\",\"Test_Score\",\"MAE\",\"MSE\",\"RMSE\",\"MAPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Train_Score</th>\n      <th>Test_Score</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>model_01</td>\n      <td>0.871079</td>\n      <td>0.861922</td>\n      <td>16640.410072</td>\n      <td>487224950.477143</td>\n      <td>22073.172642</td>\n      <td>10.795143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>model_02</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>model_03</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>model_04</td>\n      <td>0.000000</td>\n      <td>-0.003349</td>\n      <td>49645.317297</td>\n      <td>3540445067.421752</td>\n      <td>59501.639199</td>\n      <td>33.638882</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      Model  Train_Score  Test_Score          MAE               MSE  \\\n0  model_01     0.871079    0.861922 16640.410072  487224950.477143   \n1  model_02     0.000000   -0.003349 49645.317297 3540445067.421752   \n2  model_03     0.000000   -0.003349 49645.317297 3540445067.421752   \n3  model_04     0.000000   -0.003349 49645.317297 3540445067.421752   \n\n          RMSE      MAPE  \n0 22073.172642 10.795143  \n1 59501.639199 33.638882  \n2 59501.639199 33.638882  \n3 59501.639199 33.638882  "
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "lotarea_winsorized         <class 'pandas.core.series.Series'>\ntotalbsmtsf_winsorized     <class 'pandas.core.series.Series'>\nfirstflrsf_winsorized      <class 'pandas.core.series.Series'>\ngrlivarea_winsorized       <class 'pandas.core.series.Series'>\ntotrmsabvgrd_winsorized    <class 'pandas.core.series.Series'>\ngaragecars_winsorized      <class 'pandas.core.series.Series'>\ngaragearea_winsorized      <class 'pandas.core.series.Series'>\nneighborhood_Blueste       <class 'pandas.core.series.Series'>\nneighborhood_BrDale        <class 'pandas.core.series.Series'>\nneighborhood_BrkSide       <class 'pandas.core.series.Series'>\nneighborhood_ClearCr       <class 'pandas.core.series.Series'>\nneighborhood_CollgCr       <class 'pandas.core.series.Series'>\nneighborhood_Crawfor       <class 'pandas.core.series.Series'>\nneighborhood_Edwards       <class 'pandas.core.series.Series'>\nneighborhood_Gilbert       <class 'pandas.core.series.Series'>\nneighborhood_IDOTRR        <class 'pandas.core.series.Series'>\nneighborhood_MeadowV       <class 'pandas.core.series.Series'>\nneighborhood_Mitchel       <class 'pandas.core.series.Series'>\nneighborhood_NAmes         <class 'pandas.core.series.Series'>\nneighborhood_NPkVill       <class 'pandas.core.series.Series'>\nneighborhood_NWAmes        <class 'pandas.core.series.Series'>\nneighborhood_NoRidge       <class 'pandas.core.series.Series'>\nneighborhood_NridgHt       <class 'pandas.core.series.Series'>\nneighborhood_OldTown       <class 'pandas.core.series.Series'>\nneighborhood_SWISU         <class 'pandas.core.series.Series'>\nneighborhood_Sawyer        <class 'pandas.core.series.Series'>\nneighborhood_SawyerW       <class 'pandas.core.series.Series'>\nneighborhood_Somerst       <class 'pandas.core.series.Series'>\nneighborhood_StoneBr       <class 'pandas.core.series.Series'>\nneighborhood_Timber        <class 'pandas.core.series.Series'>\nneighborhood_Veenker       <class 'pandas.core.series.Series'>\noverallqual_2              <class 'pandas.core.series.Series'>\noverallqual_3              <class 'pandas.core.series.Series'>\noverallqual_4              <class 'pandas.core.series.Series'>\noverallqual_5              <class 'pandas.core.series.Series'>\noverallqual_6              <class 'pandas.core.series.Series'>\noverallqual_7              <class 'pandas.core.series.Series'>\noverallqual_8              <class 'pandas.core.series.Series'>\noverallqual_9              <class 'pandas.core.series.Series'>\noverallqual_10             <class 'pandas.core.series.Series'>\ngaragecars_garagearea      <class 'pandas.core.series.Series'>\ndtype: object\n"
    }
   ],
   "source": [
    "print(X.apply(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}