{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2019-11-13 09:08:33,518 INFO sqlalchemy.engine.base.Engine select version()\n2019-11-13 09:08:33,520 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:08:33,616 INFO sqlalchemy.engine.base.Engine select current_schema()\n2019-11-13 09:08:33,620 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:08:33,716 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n2019-11-13 09:08:33,719 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:08:33,772 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n2019-11-13 09:08:33,774 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:08:33,829 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n2019-11-13 09:08:33,831 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:08:33,936 INFO sqlalchemy.engine.base.Engine SELECT * FROM youtube\n2019-11-13 09:08:33,942 INFO sqlalchemy.engine.base.Engine {}\n"
    }
   ],
   "source": [
    "kagle = dict(\n",
    "    drivername=\"postgresql\", \n",
    "    username=\"dsbc_student\", \n",
    "    password=\"7*.8G9QH21\", \n",
    "    host=\"142.93.121.174\", \n",
    "    port=\"5432\", \n",
    "    database=\"youtube\"\n",
    ")\n",
    "\n",
    "engine=create_engine(URL(**kagle), echo=True)\n",
    "\n",
    "youtube_df = pd.read_sql_query(\"SELECT * FROM youtube\", con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 6 columns):\nRank             5000 non-null object\nGrade            5000 non-null object\nChannel name     5000 non-null object\nVideo Uploads    5000 non-null object\nSubscribers      5000 non-null object\nVideo views      5000 non-null int64\ndtypes: int64(1), object(5)\nmemory usage: 234.5+ KB\n"
    }
   ],
   "source": [
    "youtube_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Uniques values in column Rank are: ['1st' '2nd' '3rd' ... '4,998th' '4,999th' '5,000th']\nUniques values in column Grade are: ['A++ ' 'A+ ' 'A ' '\\xa0 ' 'A- ' 'B+ ']\nUniques values in column Channel name are: ['Zee TV' 'T-Series' 'Cocomelon - Nursery Rhymes' ... 'Mastersaint'\n 'Bruce McIntosh' 'SehatAQUA']\nUniques values in column Video Uploads are: ['82757' '12661' '373' ... '1735' '706' '3475']\nUniques values in column Subscribers are: ['18752951' '61196302' '19238251' ... '3265735' '32990' '21172']\nUniques values in column Video views are: [20869786591 47548839843  9793305082 ...   311758426    14563764\n    73312511]\n"
    }
   ],
   "source": [
    "# Detecting missing values\n",
    "for column_name in youtube_df.columns:\n",
    "    print(f\"Uniques values in column {column_name} are: {youtube_df[column_name].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "These are the problematice values for the variable: Video Uploads\n--\n--\n--\n--\n--\n--\nThese are the problematice values for the variable: Subscribers\n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n-- \n"
    }
   ],
   "source": [
    "# print all values that cannot be converted to float\n",
    "for column_name in [\"Video Uploads\",\"Subscribers\"]: \n",
    "    print(f\"These are the problematic values for the variable: {column_name}\")\n",
    "    for value in youtube_df[column_name]:\n",
    "        try:\n",
    "            float(value)\n",
    "        except:\n",
    "            print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 6 columns):\nRank             5000 non-null object\nGrade            5000 non-null object\nChannel name     5000 non-null object\nVideo Uploads    4994 non-null float32\nSubscribers      4613 non-null float32\nVideo views      5000 non-null int64\ndtypes: float32(2), int64(1), object(3)\nmemory usage: 195.4+ KB\n"
    }
   ],
   "source": [
    "# Rplace \"--\" values with empty strings\n",
    "for column_name in [\"Video Uploads\",\"Subscribers\"]:\n",
    "    try:\n",
    "        youtube_df[column_name] = youtube_df[column_name].apply(str.strip).replace(\"--\", np.nan)\n",
    "        youtube_df[column_name] = pd.to_numeric(youtube_df[column_name], downcast=\"float\")\n",
    "    except:\n",
    "        print(\"No strings to replace\")\n",
    "\n",
    "youtube_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Rank             0.00\nGrade            0.00\nChannel name     0.00\nVideo Uploads    0.12\nSubscribers      7.74\nVideo views      0.00\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentages of missing values in all columns\n",
    "youtube_df.isnull().sum()*100/youtube_df.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "B+      2956\nA-      1024\nA        963\nA+        41\nA++       10\nÂ           6\nName: Grade, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for nulls in categorical columns\n",
    "youtube_df[\"Grade\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['A++', 'A+', 'A', nan, 'A-', 'B+'], dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace empty strings with np.nan\n",
    "youtube_df[\"Grade\"] = youtube_df[\"Grade\"].apply(str.strip).replace(\"\", np.nan)\n",
    "\n",
    "# Print a new list of unique values\n",
    "youtube_df[\"Grade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the \"Video Uploads\" and \"Subscribers\" columns with mean values\n",
    "for column_name in [\"Video Uploads\",\"Subscribers\"]:\n",
    "    try:\n",
    "        youtube_df[column_name].fillna(youtube_df[column_name].mean(), inplace=True)\n",
    "    except:\n",
    "        print(\"No values could be replaced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Rank             0.000000\nGrade            0.120144\nChannel name     0.000000\nVideo Uploads    0.000000\nSubscribers      0.000000\nVideo views      0.000000\ndtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run null percentages\n",
    "youtube_df.isnull().sum()*100/youtube_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['A++', 'A+', 'A', 'A-', 'B+'], dtype=object)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing values\n",
    "grade_list = youtube_df[\"Grade\"]\n",
    "\n",
    "for i in range(0, len(youtube_df[\"Grade\"])):\n",
    "    if pd.isnull(youtube_df[\"Grade\"][i]):\n",
    "        youtube_df[\"Grade\"][i] = youtube_df[\"Grade\"][i-1]\n",
    "\n",
    "youtube_df[\"Grade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Rank             0.0\nGrade            0.0\nChannel name     0.0\nVideo Uploads    0.0\nSubscribers      0.0\nVideo views      0.0\ndtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run null percentages\n",
    "youtube_df.isnull().sum()*100/youtube_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2019-11-13 09:44:01,160 INFO sqlalchemy.engine.base.Engine select version()\n2019-11-13 09:44:01,162 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:44:01,261 INFO sqlalchemy.engine.base.Engine select current_schema()\n2019-11-13 09:44:01,262 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:44:01,364 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n2019-11-13 09:44:01,365 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:44:01,420 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n2019-11-13 09:44:01,421 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:44:01,468 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n2019-11-13 09:44:01,468 INFO sqlalchemy.engine.base.Engine {}\n2019-11-13 09:44:01,564 INFO sqlalchemy.engine.base.Engine SELECT * FROM useducation\n2019-11-13 09:44:01,565 INFO sqlalchemy.engine.base.Engine {}\n"
    }
   ],
   "source": [
    "kagle = dict(\n",
    "    drivername=\"postgresql\", \n",
    "    username=\"dsbc_student\", \n",
    "    password=\"7*.8G9QH21\", \n",
    "    host=\"142.93.121.174\", \n",
    "    port=\"5432\", \n",
    "    database=\"useducation\"\n",
    ")\n",
    "\n",
    "engine=create_engine(URL(**kagle), echo=True)\n",
    "\n",
    "education_df = pd.read_sql_query(\"SELECT * FROM useducation\", con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1. Determine all variable types and find the fraction of the missing values for each variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1492 entries, 0 to 1491\nData columns (total 25 columns):\nPRIMARY_KEY                     1492 non-null object\nSTATE                           1492 non-null object\nYEAR                            1492 non-null int64\nENROLL                          1229 non-null float64\nTOTAL_REVENUE                   1280 non-null float64\nFEDERAL_REVENUE                 1280 non-null float64\nSTATE_REVENUE                   1280 non-null float64\nLOCAL_REVENUE                   1280 non-null float64\nTOTAL_EXPENDITURE               1280 non-null float64\nINSTRUCTION_EXPENDITURE         1280 non-null float64\nSUPPORT_SERVICES_EXPENDITURE    1280 non-null float64\nOTHER_EXPENDITURE               1229 non-null float64\nCAPITAL_OUTLAY_EXPENDITURE      1280 non-null float64\nGRADES_PK_G                     1319 non-null float64\nGRADES_KG_G                     1360 non-null float64\nGRADES_4_G                      1361 non-null float64\nGRADES_8_G                      1361 non-null float64\nGRADES_12_G                     1361 non-null float64\nGRADES_1_8_G                    1361 non-null float64\nGRADES_9_12_G                   1361 non-null float64\nGRADES_ALL_G                    1319 non-null float64\nAVG_MATH_4_SCORE                536 non-null float64\nAVG_MATH_8_SCORE                532 non-null float64\nAVG_READING_4_SCORE             533 non-null float64\nAVG_READING_8_SCORE             498 non-null float64\ndtypes: float64(22), int64(1), object(2)\nmemory usage: 291.5+ KB\n"
    }
   ],
   "source": [
    "education_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRIMARY_KEY</th>\n      <th>STATE</th>\n      <th>YEAR</th>\n      <th>ENROLL</th>\n      <th>TOTAL_REVENUE</th>\n      <th>FEDERAL_REVENUE</th>\n      <th>STATE_REVENUE</th>\n      <th>LOCAL_REVENUE</th>\n      <th>TOTAL_EXPENDITURE</th>\n      <th>INSTRUCTION_EXPENDITURE</th>\n      <th>...</th>\n      <th>GRADES_4_G</th>\n      <th>GRADES_8_G</th>\n      <th>GRADES_12_G</th>\n      <th>GRADES_1_8_G</th>\n      <th>GRADES_9_12_G</th>\n      <th>GRADES_ALL_G</th>\n      <th>AVG_MATH_4_SCORE</th>\n      <th>AVG_MATH_8_SCORE</th>\n      <th>AVG_READING_4_SCORE</th>\n      <th>AVG_READING_8_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1060</td>\n      <td>2012_IOWA</td>\n      <td>IOWA</td>\n      <td>2012</td>\n      <td>495870.0</td>\n      <td>6262807.0</td>\n      <td>512246.0</td>\n      <td>2681035.0</td>\n      <td>3069526.0</td>\n      <td>6256926.0</td>\n      <td>3072424.0</td>\n      <td>...</td>\n      <td>35492.0</td>\n      <td>35694.0</td>\n      <td>36254.0</td>\n      <td>285931.0</td>\n      <td>144784.0</td>\n      <td>458444.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1104</td>\n      <td>2013_DELAWARE</td>\n      <td>DELAWARE</td>\n      <td>2013</td>\n      <td>118685.0</td>\n      <td>1930466.0</td>\n      <td>151096.0</td>\n      <td>1124112.0</td>\n      <td>655258.0</td>\n      <td>1924626.0</td>\n      <td>1030897.0</td>\n      <td>...</td>\n      <td>10069.0</td>\n      <td>9993.0</td>\n      <td>8536.0</td>\n      <td>81303.0</td>\n      <td>38483.0</td>\n      <td>121199.0</td>\n      <td>243.107758</td>\n      <td>282.338299</td>\n      <td>225.771651</td>\n      <td>271.009087</td>\n    </tr>\n    <tr>\n      <td>421</td>\n      <td>2000_COLORADO</td>\n      <td>COLORADO</td>\n      <td>2000</td>\n      <td>707436.0</td>\n      <td>5073266.0</td>\n      <td>266207.0</td>\n      <td>2083318.0</td>\n      <td>2723741.0</td>\n      <td>5444193.0</td>\n      <td>2539372.0</td>\n      <td>...</td>\n      <td>57056.0</td>\n      <td>55384.0</td>\n      <td>43502.0</td>\n      <td>450150.0</td>\n      <td>207942.0</td>\n      <td>673469.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>259.564238</td>\n    </tr>\n    <tr>\n      <td>1457</td>\n      <td>2017_GEORGIA</td>\n      <td>GEORGIA</td>\n      <td>2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>236.383603</td>\n      <td>281.035488</td>\n      <td>219.682925</td>\n      <td>266.553369</td>\n    </tr>\n    <tr>\n      <td>1097</td>\n      <td>2017_OREGON</td>\n      <td>OREGON</td>\n      <td>2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>233.132460</td>\n      <td>282.173028</td>\n      <td>217.531073</td>\n      <td>261.236934</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã 25 columns</p>\n</div>",
      "text/plain": "        PRIMARY_KEY     STATE  YEAR    ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n1060      2012_IOWA      IOWA  2012  495870.0      6262807.0         512246.0   \n1104  2013_DELAWARE  DELAWARE  2013  118685.0      1930466.0         151096.0   \n421   2000_COLORADO  COLORADO  2000  707436.0      5073266.0         266207.0   \n1457   2017_GEORGIA   GEORGIA  2017       NaN            NaN              NaN   \n1097    2017_OREGON    OREGON  2017       NaN            NaN              NaN   \n\n      STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n1060      2681035.0      3069526.0          6256926.0   \n1104      1124112.0       655258.0          1924626.0   \n421       2083318.0      2723741.0          5444193.0   \n1457            NaN            NaN                NaN   \n1097            NaN            NaN                NaN   \n\n      INSTRUCTION_EXPENDITURE  ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  \\\n1060                3072424.0  ...     35492.0     35694.0      36254.0   \n1104                1030897.0  ...     10069.0      9993.0       8536.0   \n421                 2539372.0  ...     57056.0     55384.0      43502.0   \n1457                      NaN  ...         NaN         NaN          NaN   \n1097                      NaN  ...         NaN         NaN          NaN   \n\n      GRADES_1_8_G  GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  \\\n1060      285931.0       144784.0      458444.0               NaN   \n1104       81303.0        38483.0      121199.0        243.107758   \n421       450150.0       207942.0      673469.0               NaN   \n1457           NaN            NaN           NaN        236.383603   \n1097           NaN            NaN           NaN        233.132460   \n\n      AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n1060               NaN                  NaN                  NaN  \n1104        282.338299           225.771651           271.009087  \n421                NaN                  NaN           259.564238  \n1457        281.035488           219.682925           266.553369  \n1097        282.173028           217.531073           261.236934  \n\n[5 rows x 25 columns]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at a random sample of rows to get a feel for the data\n",
    "education_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"PRIMARY_KEY\" & \"STATE\" columns appear to be categorical columns split them off and examine the separately\n",
    "categorical_cols = education_df.select_dtypes(include='object').columns\n",
    "continuous_cols = education_df.select_dtypes(exclude='object').columns\n",
    "\n",
    "# Create some variables for calculation\n",
    "df_len = len(education_df)\n",
    "max_col = len(max(education_df.columns, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "first five shortest strings in 'PRIMARY_KEY': ['2012_BI', '2012_DD', '1998_BI', '1998_DD', '1998_AS'] \n\nfirst five shortest strings in 'STATE': ['BI', 'DD', 'AS', 'GU', 'MP'] \n\nPRIMARY_KEY                 :     0 nulls | percent null:  0.00\nSTATE                       :     0 nulls | percent null:  0.00\n"
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    vals = sorted(education_df[col].unique(), key=len)\n",
    "    print(f\"first five shortest strings in '{col}': {vals[:5]} \\n\")    \n",
    "\n",
    "# Look at null value information for continuous variables\n",
    "for col in categorical_cols:\n",
    "    empty_strings = len(education_df.loc[education_df[col]==''])\n",
    "    nulls = education_df[col].isna().sum()\n",
    "    tot_nulls = empty_strings + nulls\n",
    "    pct_nan = tot_nulls*100/df_len\n",
    "    print(f\"{col:<{max_col}}: {tot_nulls:>{5}} nulls | percent null: {pct_nan:>{5}.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "YEAR                        :     0 nulls | percent null:  0.00\nENROLL                      :   263 nulls | percent null: 17.63\nTOTAL_REVENUE               :   212 nulls | percent null: 14.21\nFEDERAL_REVENUE             :   212 nulls | percent null: 14.21\nSTATE_REVENUE               :   212 nulls | percent null: 14.21\nLOCAL_REVENUE               :   212 nulls | percent null: 14.21\nTOTAL_EXPENDITURE           :   212 nulls | percent null: 14.21\nINSTRUCTION_EXPENDITURE     :   212 nulls | percent null: 14.21\nSUPPORT_SERVICES_EXPENDITURE:   212 nulls | percent null: 14.21\nOTHER_EXPENDITURE           :   263 nulls | percent null: 17.63\nCAPITAL_OUTLAY_EXPENDITURE  :   212 nulls | percent null: 14.21\nGRADES_PK_G                 :   173 nulls | percent null: 11.60\nGRADES_KG_G                 :   132 nulls | percent null:  8.85\nGRADES_4_G                  :   131 nulls | percent null:  8.78\nGRADES_8_G                  :   131 nulls | percent null:  8.78\nGRADES_12_G                 :   131 nulls | percent null:  8.78\nGRADES_1_8_G                :   131 nulls | percent null:  8.78\nGRADES_9_12_G               :   131 nulls | percent null:  8.78\nGRADES_ALL_G                :   173 nulls | percent null: 11.60\nAVG_MATH_4_SCORE            :   956 nulls | percent null: 64.08\nAVG_MATH_8_SCORE            :   960 nulls | percent null: 64.34\nAVG_READING_4_SCORE         :   959 nulls | percent null: 64.28\nAVG_READING_8_SCORE         :   994 nulls | percent null: 66.62\n"
    }
   ],
   "source": [
    "# Look a null value information for continuous variables\n",
    "for col in continuous_cols:\n",
    "    nulls = education_df[col].isnull().sum()\n",
    "    pct_null = nulls*100/df_len\n",
    "    print(f\"{col:<{max_col}}: {nulls:>{5}} nulls | percent null: {pct_null:>{5}.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When reviewing the education_df the null values appear to concentrated in the continuous variables.  With regard to the categorical variables there are no null or nan values."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?_\n",
    "\n",
    "I am inclined to use Imputation of the mean for columns 'ENROLL', 'TOTAL_REVENUE', 'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE', 'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE', 'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE', 'CAPITAL_OUTLAY_EXPENDITURE', 'GRADES_PK_G', 'GRADES_KG_G', 'GRADES_4_G', 'GRADES_8_G', 'GRADES_12_G', 'GRADES_1_8_G', 'GRADES_9_12_G', & 'GRADES_ALL_G'.  It is my belief that using imputation on these columns would be reasonable at most 17.62% of records would see an impact by filling nulls with imputation.  I would consider dropping the columns: 'AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE', 'AVG_READING_4_SCORE', & 'AVG_READING_8_SCORE' because using the data in these columns would have a substantial impact on conclusions drawn from their inclusion in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the continuious variable columns to a list \n",
    "replace_cols = list(continuous_cols)\n",
    "\n",
    "# Do not consider the year column for replacement\n",
    "replace_cols.remove('YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1492 entries, 0 to 1491\nData columns (total 21 columns):\nPRIMARY_KEY                     1492 non-null object\nSTATE                           1492 non-null object\nYEAR                            1492 non-null int64\nENROLL                          1492 non-null float64\nTOTAL_REVENUE                   1492 non-null float64\nFEDERAL_REVENUE                 1492 non-null float64\nSTATE_REVENUE                   1492 non-null float64\nLOCAL_REVENUE                   1492 non-null float64\nTOTAL_EXPENDITURE               1492 non-null float64\nINSTRUCTION_EXPENDITURE         1492 non-null float64\nSUPPORT_SERVICES_EXPENDITURE    1492 non-null float64\nOTHER_EXPENDITURE               1492 non-null float64\nCAPITAL_OUTLAY_EXPENDITURE      1492 non-null float64\nGRADES_PK_G                     1492 non-null float64\nGRADES_KG_G                     1492 non-null float64\nGRADES_4_G                      1492 non-null float64\nGRADES_8_G                      1492 non-null float64\nGRADES_12_G                     1492 non-null float64\nGRADES_1_8_G                    1492 non-null float64\nGRADES_9_12_G                   1492 non-null float64\nGRADES_ALL_G                    1492 non-null float64\ndtypes: float64(18), int64(1), object(2)\nmemory usage: 244.9+ KB\n"
    }
   ],
   "source": [
    "# Make a copy of the education_df to work on as you'll want to perform replacement several more times.\n",
    "ed_replace1 = education_df\n",
    "for col in replace_cols:\n",
    "    try:\n",
    "        ed_replace1[col].fillna(ed_replace1[col].mean(), inplace=True)\n",
    "    except:\n",
    "        print(\"No values could be replaced.\")\n",
    "\n",
    "ed_replace1 = ed_replace1.drop(columns=[\"AVG_MATH_4_SCORE\",\"AVG_MATH_8_SCORE\",\"AVG_READING_4_SCORE\",\"AVG_READING_8_SCORE\"])\n",
    "\n",
    "ed_replace1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1492 entries, 0 to 1491\nData columns (total 25 columns):\nPRIMARY_KEY                     1492 non-null object\nSTATE                           1492 non-null object\nYEAR                            1492 non-null int64\nENROLL                          1492 non-null float64\nTOTAL_REVENUE                   1492 non-null float64\nFEDERAL_REVENUE                 1492 non-null float64\nSTATE_REVENUE                   1492 non-null float64\nLOCAL_REVENUE                   1492 non-null float64\nTOTAL_EXPENDITURE               1492 non-null float64\nINSTRUCTION_EXPENDITURE         1492 non-null float64\nSUPPORT_SERVICES_EXPENDITURE    1492 non-null float64\nOTHER_EXPENDITURE               1492 non-null float64\nCAPITAL_OUTLAY_EXPENDITURE      1492 non-null float64\nGRADES_PK_G                     1492 non-null float64\nGRADES_KG_G                     1492 non-null float64\nGRADES_4_G                      1492 non-null float64\nGRADES_8_G                      1492 non-null float64\nGRADES_12_G                     1492 non-null float64\nGRADES_1_8_G                    1492 non-null float64\nGRADES_9_12_G                   1492 non-null float64\nGRADES_ALL_G                    1492 non-null float64\nAVG_MATH_4_SCORE                1492 non-null float64\nAVG_MATH_8_SCORE                1492 non-null float64\nAVG_READING_4_SCORE             1492 non-null float64\nAVG_READING_8_SCORE             1492 non-null float64\ndtypes: float64(22), int64(1), object(2)\nmemory usage: 291.5+ KB\n"
    }
   ],
   "source": [
    "replace_cols2 = education_df\n",
    "year_list = education_df['YEAR'].unique()\n",
    "\n",
    "for col in replace_cols:\n",
    "    for year in year_list:\n",
    "        replace_cols2.loc[replace_cols2['YEAR']==year, col] = replace_cols2.loc[replace_cols2['YEAR']==year,col].fillna(replace_cols2[replace_cols2['YEAR']==year][col].mean())\n",
    "\n",
    "replace_cols2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_4. This time, fill in the missing values using interpolation (extrapolation)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1492 entries, 0 to 1491\nData columns (total 25 columns):\nPRIMARY_KEY                     1492 non-null object\nSTATE                           1492 non-null object\nYEAR                            1492 non-null int64\nENROLL                          1492 non-null float64\nTOTAL_REVENUE                   1492 non-null float64\nFEDERAL_REVENUE                 1492 non-null float64\nSTATE_REVENUE                   1492 non-null float64\nLOCAL_REVENUE                   1492 non-null float64\nTOTAL_EXPENDITURE               1492 non-null float64\nINSTRUCTION_EXPENDITURE         1492 non-null float64\nSUPPORT_SERVICES_EXPENDITURE    1492 non-null float64\nOTHER_EXPENDITURE               1492 non-null float64\nCAPITAL_OUTLAY_EXPENDITURE      1492 non-null float64\nGRADES_PK_G                     1492 non-null float64\nGRADES_KG_G                     1492 non-null float64\nGRADES_4_G                      1492 non-null float64\nGRADES_8_G                      1492 non-null float64\nGRADES_12_G                     1492 non-null float64\nGRADES_1_8_G                    1492 non-null float64\nGRADES_9_12_G                   1492 non-null float64\nGRADES_ALL_G                    1492 non-null float64\nAVG_MATH_4_SCORE                1492 non-null float64\nAVG_MATH_8_SCORE                1492 non-null float64\nAVG_READING_4_SCORE             1492 non-null float64\nAVG_READING_8_SCORE             1492 non-null float64\ndtypes: float64(22), int64(1), object(2)\nmemory usage: 291.5+ KB\n"
    }
   ],
   "source": [
    "# Fill missing values via interolation\n",
    "replace_cols3 = education_df\n",
    "col_list = replace_cols3.columns\n",
    "\n",
    "for col in col_list:\n",
    "    for i in range(0, len(replace_cols3[col])):\n",
    "        if pd.isnull(replace_cols3[col][i]): \n",
    "            replace_cols3[col][i] = replace_cols3[col][i-1]\n",
    "\n",
    "replace_cols3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Set Means:\nColumn                           Set 1 Mean |    Set 2 Mean |    Set 3 Mean\nENROLL                      :    915,930.82 |    915,930.82 |    915,930.82\nTOTAL_REVENUE               :  9,092,081.86 |  9,092,081.86 |  9,092,081.86\nFEDERAL_REVENUE             :    766,372.34 |    766,372.34 |    766,372.34\nSTATE_REVENUE               :  4,216,552.95 |  4,216,552.95 |  4,216,552.95\n\nSet Medians:\nColumn                         Set 1 Median |  Set 2 Median |  Set 3 Median\nENROLL                      :    820,414.00 |    820,414.00 |    820,414.00\nTOTAL_REVENUE               :  6,359,310.50 |  6,359,310.50 |  6,359,310.50\nFEDERAL_REVENUE             :    516,741.00 |    516,741.00 |    516,741.00\nSTATE_REVENUE               :  3,127,639.00 |  3,127,639.00 |  3,127,639.00\n\nSet Modes:\nColumn                           Set 1 Mode |    Set 2 Mode |    Set 3 Mode\nENROLL                      :    915,930.82 |    915,930.82 |    915,930.82\nTOTAL_REVENUE               :  9,092,081.86 |  9,092,081.86 |  9,092,081.86\nFEDERAL_REVENUE             :    766,372.34 |    766,372.34 |    766,372.34\nSTATE_REVENUE               :  4,216,552.95 |  4,216,552.95 |  4,216,552.95\n\nSet Standard Deviation:\nColumn                        Set 1 Std Dev | Set 2 Std Dev | Set 3 Std Dev\nENROLL                      :    966,772.54 |    966,772.54 |    966,772.54\nTOTAL_REVENUE               : 10,878,184.01 | 10,878,184.01 | 10,878,184.01\nFEDERAL_REVENUE             :  1,060,702.42 |  1,060,702.42 |  1,060,702.42\nSTATE_REVENUE               :  5,133,894.86 |  5,133,894.86 |  5,133,894.86\n"
    }
   ],
   "source": [
    "selected_data = [\"ENROLL\",\"TOTAL_REVENUE\",\"FEDERAL_REVENUE\",\"STATE_REVENUE\"]\n",
    "\n",
    "stat_set1 = ed_replace1[selected_data]\n",
    "stat_set2 = replace_cols2[selected_data]\n",
    "stat_set3 = replace_cols3[selected_data]\n",
    "\n",
    "stat_sets = [stat_set1, stat_set2, stat_set3]\n",
    "\n",
    "print(\"Set Means:\")\n",
    "print(f\"{'Column':<{max_col+2}}{'Set 1 Mean':>{13}} | {'Set 2 Mean':>{13}} | {'Set 3 Mean':>{13}}\")\n",
    "for col in selected_data:    \n",
    "    print(f\"{col:<{max_col}}: {stat_set1[col].mean():>{13},.2f} | {stat_set2[col].mean():>{13},.2f} | {stat_set3[col].mean():>{13},.2f}\")\n",
    "\n",
    "print(\"\\nSet Medians:\")\n",
    "print(f\"{'Column':<{max_col+2}}{'Set 1 Median':>{13}} | {'Set 2 Median':>{13}} | {'Set 3 Median':>{13}}\")\n",
    "for col in selected_data:    \n",
    "    print(f\"{col:<{max_col}}: {stat_set1[col].median():>{13},.2f} | {stat_set2[col].median():>{13},.2f} | {stat_set3[col].median():>{13},.2f}\")\n",
    "\n",
    "print(\"\\nSet Modes:\")\n",
    "print(f\"{'Column':<{max_col+2}}{'Set 1 Mode':>{13}} | {'Set 2 Mode':>{13}} | {'Set 3 Mode':>{13}}\")\n",
    "for col in selected_data:    \n",
    "    print(f\"{col:<{max_col}}: {stat_set1[col].mode()[0]:>{13},.2f} | {stat_set2[col].mode()[0]:>{13},.2f} | {stat_set3[col].mode()[0]:>{13},.2f}\")\n",
    "\n",
    "print(\"\\nSet Standard Deviation:\")\n",
    "print(f\"{'Column':<{max_col+2}}{'Set 1 Std Dev':>{13}} | {'Set 2 Std Dev':>{13}} | {'Set 3 Std Dev':>{13}}\")\n",
    "for col in selected_data:    \n",
    "    print(f\"{col:<{max_col}}: {stat_set1[col].std():>{13},.2f} | {stat_set2[col].std():>{13},.2f} | {stat_set3[col].std():>{13},.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}