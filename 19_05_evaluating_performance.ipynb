{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19.05 Evaluating Performance\n",
    "\n",
    "# 19.05 Evaluating Performance\n",
    "\n",
    "So far, in module 19, you’ve learned how to build linear regression models and interpret estimated coefficients.  In this notebook the discussion turns to how you evaluate model performance in the training phase.  Recall that there are two contexts where you care about performance: in relation to the training set and in relations to a test set.  The former enables you to talk about how well the model explains the information in the garget variable, while the latter tells you how well the model will perform when its given previously unseen observations.  \n",
    "\n",
    "In this notebook concepts lite **F-tests** and **R-squared** are covered.  F-tests ally you to compare your model to a reduced model with no features.  R-squared and **adjusted R-squared** (which is a variant of R-squared) values tell you how well the model accounts for variance in the target.\n",
    "\n",
    "Last, you'll see how you can compare different models in terms of their explanatory power.  The notebook will show you how to read **Akaike** and **Bayesian** information criteria for this purpose.  \n",
    "\n",
    "#### **Key Topics**\n",
    "- training and test data\n",
    "- evaluating training Performance\n",
    "- F-tests\n",
    "- degrees of freedom\n",
    "- R-squared\n",
    "- Akaike information criterion\n",
    "- Bayesian information criterion\n",
    "\n",
    "## Is Your Model Better Than an \"Empty\" Model?\n",
    "\n",
    "When evaluating your model, you first need to ask whether your model contributes anything to the explanation of the outcome variable.  In other words, you need to determine whether your features explain variance in the outcome.  If not, you could drop your features altogether and the resulting \"empty\" model would perform equally well (which is to say, not very well).  For this purpose, you use an **F-test**.\n",
    "\n",
    "#### F-tests\n",
    "\n",
    "F-tests can be calculated in different ways depending on the situation, but, in general, they represent the ration between a model's unexplained variance compared to a reduced model.  Here the \"reduced model\" is a model with no features, meaning all variance in the outcome is unexplained.  For a linear regression model with two parameters $y = \\alpha + \\beta_x$, the F-test is built from these pieces: \n",
    "- unexplained model variance: $SSE_F=\\sum(y_i-\\hat{y}_i)^2$\n",
    "- unexplained variance in reduced model: $SSE_R=Var_y = \\sum(y_i-\\bar{y})^2$\n",
    "- number of parameters in the model: $p_F = 2 (\\alpha \\text{ and } \\beta)$\n",
    "- number of parameters in the reduced model: $p_R = 1 (\\alpha)$\n",
    "- number of observations: $n$\n",
    "- degrees of freedom $SSE_F$: $df_F = n - p_F$\n",
    "- degrees of freedom of $SSE_R$: $df_R = n - p_R$\n",
    "\n",
    "These pieces come together to give you the full equation for the F-test: \n",
    "$$F=\\dfrac{SSE_F-SSE_R}{df_F-df_R}÷\\dfrac{SSE_F}{df_F}$$\n",
    "\n",
    "**Degrees of Freedom** quantifies the amount of information \"left over\" to estimate variable after all parameters are estimated.\n",
    "\n",
    "In regression, degrees of freedom for a function works like this:  With two data points, a regression $y = \\alpha + \\beta_x$ has $0$ degrees of freedom ($2$ minus the number of parameters).  Those two parameters encompass all the information in the data.  Knowing $\\alpha$ and $\\beta$ alone, you can perfectly reproduce the original data.  No additional information is available from the data itself.  If you have 10 data points, then the model's degrees of freedom would be $8$ ($10$ minus the number of parameters).\n",
    "\n",
    "The F-test null hypothesis states that the mode is indistinguishable from the reduced model, which means that the features contribute nothing to the explanation of the target variable.  Instead of reading the F statistic, it's easier to read it's associated p-value.  The lower the p-value, the better for your model.  Namely, if the p-value of the F-test for your model is $\\leq 0.1$ (or even $\\leq 0.05$), you can say that your model is useful and contributes something that is statistically significant in the explanation of the target.\n",
    "\n",
    "Now, look and see the F statistic in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "kagle = dict(\n",
    "    drivername = \"postgresql\",\n",
    "    username = \"dsbc_student\",\n",
    "    password = \"7*.8G9QH21\",\n",
    "    host = \"142.93.121.174\",\n",
    "    port = \"5432\",\n",
    "    database = \"medicalcosts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-06 16:29:40,342 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2020-01-06 16:29:40,350 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-06 16:29:40,452 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2020-01-06 16:29:40,454 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-06 16:29:40,553 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-01-06 16:29:40,554 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-06 16:29:40,604 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-01-06 16:29:40,605 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-06 16:29:40,655 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2020-01-06 16:29:40,657 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-06 16:29:40,758 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-01-06 16:29:40,760 INFO sqlalchemy.engine.base.Engine {'name': 'SELECT * FROM medicalcosts'}\n",
      "2020-01-06 16:29:40,912 INFO sqlalchemy.engine.base.Engine SELECT * FROM medicalcosts\n",
      "2020-01-06 16:29:40,914 INFO sqlalchemy.engine.base.Engine {}\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the medicalcosts database\n",
    "engine=create_engine(URL(**kagle), echo=True)\n",
    "\n",
    "insurance_df = pd.read_sql(\"SELECT * FROM medicalcosts\", con=engine)\n",
    "\n",
    "# No need for an open connection, please close\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>20.520</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northeast</td>\n",
       "      <td>14571.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>33.915</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>9866.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>22.515</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>2117.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>26.180</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>7046.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>43.120</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4753.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>28.300</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>17081.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>28.310</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>7153.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>43</td>\n",
       "      <td>female</td>\n",
       "      <td>26.700</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>22478.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>22.230</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>12029.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>42</td>\n",
       "      <td>male</td>\n",
       "      <td>26.125</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>7729.650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex    bmi  children smoker     region   charges\n",
       "989    24  female 20.520         0    yes  northeast 14571.900\n",
       "522    51  female 33.915         0     no  northeast  9866.300\n",
       "899    19  female 22.515         0     no  northwest  2117.340\n",
       "800    42  female 26.180         1     no  southeast  7046.720\n",
       "572    30  female 43.120         2     no  southeast  4753.640\n",
       "126    19  female 28.300         0    yes  southwest 17081.100\n",
       "1164   41  female 28.310         1     no  northwest  7153.550\n",
       "1171   43  female 26.700         2    yes  southwest 22478.600\n",
       "371    57  female 22.230         0     no  northeast 12029.300\n",
       "686    42    male 26.125         2     no  northeast  7729.650"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at a sample of the data\n",
    "insurance_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some dummy columns for the categorical data found in the \"sex\" & \"smoker\" variables\n",
    "insurance_df[\"is_male\"] = pd.get_dummies(insurance_df[\"sex\"], drop_first=True)\n",
    "insurance_df[\"is_smoker\"] = pd.get_dummies(insurance_df[\"smoker\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     986.5\n",
      "Date:                Mon, 06 Jan 2020   Prob (F-statistic):               0.00\n",
      "Time:                        16:34:13   Log-Likelihood:                -13557.\n",
      "No. Observations:                1338   AIC:                         2.712e+04\n",
      "Df Residuals:                    1333   BIC:                         2.715e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.163e+04    947.267    -12.281      0.000   -1.35e+04   -9775.195\n",
      "is_male     -109.0414    334.665     -0.326      0.745    -765.568     547.486\n",
      "is_smoker   2.383e+04    414.187     57.544      0.000     2.3e+04    2.46e+04\n",
      "age          259.4531     11.942     21.727      0.000     236.027     282.880\n",
      "bmi          323.0510     27.529     11.735      0.000     269.046     377.056\n",
      "==============================================================================\n",
      "Omnibus:                      299.394   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              708.640\n",
      "Skew:                           1.212   Prob(JB):                    1.32e-154\n",
      "Kurtosis:                       5.614   Cond. No.                         292.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit an Ordinary Least Squares (OLS) model to the data\n",
    "# Y is the target variable\n",
    "Y = insurance_df[\"charges\"]\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[[\"is_male\", \"is_smoker\", \"age\", \"bmi\"]]\n",
    "\n",
    "# Add a constant to the model (best practice)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y,X).fit()\n",
    "\n",
    "# Print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's F statistic is $986.5$, and the associated p-value is very close to zero.  This means that the model's features add some information to the reduced model and the model is useful in explaining the target variable (charges).  However, F-tests don't quantify how much information your model contributes.  This requires R-squared, which is discussed next.\n",
    "\n",
    "### Quantifying the Performance of a Model on the Training Set\n",
    "\n",
    "R-squared is probably the most common measure of goodness on fit in a linear regression model.  It is a proportion (between $0$ and $1$) that expresses how much variance in the outcome variable is explained by the explanatory variables in the model.  Generally speaking higher $R^2$ values are better to a point - a low $R^2$ indicated that the model isn't explaining much information about the outcome, which means it will not give very good predictions.  However, a very high $R^2$ is a warning sign of overfitting.  No dataset is a perfect representation of reality, so a model that perfectly fits your data ($R^2$ of $1$ or close to $1$) is likely to be biased by quirks in the data and will perform less well on the test set.\n",
    "\n",
    "In the regression summary table above, you see that the R-squared value of the medical costs model is $0.747$. This means that the model explains 74.7% of the variance in the charges, leaving 25.3% unexplained.  You can conclude that there's still room for improvement.  Now, fit the model in the previous notebook, 19.04, where you included the interaction of body mass index (BMI) and is_smoking dummy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     1365.\n",
      "Date:                Mon, 06 Jan 2020   Prob (F-statistic):               0.00\n",
      "Time:                        16:52:45   Log-Likelihood:                -13265.\n",
      "No. Observations:                1338   AIC:                         2.654e+04\n",
      "Df Residuals:                    1332   BIC:                         2.657e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2071.0750    840.644     -2.464      0.014   -3720.206    -421.944\n",
      "is_male        -473.4954    269.612     -1.756      0.079   -1002.406      55.415\n",
      "is_smoker     -2.019e+04   1666.492    -12.117      0.000   -2.35e+04   -1.69e+04\n",
      "age             266.3723      9.612     27.713      0.000     247.516     285.228\n",
      "bmi               7.9686     25.044      0.318      0.750     -41.160      57.098\n",
      "bmi_is_smoker  1435.6081     53.242     26.964      0.000    1331.160    1540.056\n",
      "==============================================================================\n",
      "Omnibus:                      710.004   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4260.532\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.183   Cond. No.                         661.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = insurance_df[\"charges\"]\n",
    "\n",
    "# This is the interaction between bmi and smoking\n",
    "insurance_df[\"bmi_is_smoker\"] = insurance_df[\"bmi\"] * insurance_df[\"is_smoker\"]\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[[\"is_male\", \"is_smoker\", \"age\", \"bmi\", \"bmi_is_smoker\"]]\n",
    "\n",
    "# Add a constant to the model as it's a best practice\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y,X).fit()\n",
    "\n",
    "# Print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared of this model is $0.837$, which is higher than the previous model's, this improvement indicates that the interaction of BMI and is_smoker explains some previously unexplained variance in the charges.\n",
    "\n",
    "As stated previously, high R-squared values are generally desirable.  However, in some cases, very high R-squared values indicate some potential problems with the model.  Specifically: \n",
    "- Very high R-squared value may be a sign of overfitting.  If your model is too complex for the data, then it may overfit the training set and do a poor job on the test set.  That said, there's not an agreed upon threshold for R-squared to detect overfitting.  Instead, it required a comparison between performance on test and training data.  **If you model performs significantly worse on the test set compared to the training set, then you should suspect overfitting**.  Evaluating linear regression models on the tests set will be discussed in the next notebook, 19.06.\n",
    "- R-squared is an inherently biased estimate of the performance in the sense that the more explanatory variables added to the model, the higher the R-squared values that are returned.  This is so even if you include irrelevant variables like noises or random data.  To mitigate the problem, you usually include a metric called **adjusted R-squared** instead of R-squared.  Adjusted R-squared does the same job as R-squared, but it is adjusted according to the number of features included in the model.  Hence, **it's always safer to look at the adjusted R-squared value instead of the R-squared value.\n",
    "\n",
    "\\*A note on negative R-squared values: it is possible to get negative R-squared values for some models.  In general terms, if a model is weaker than a straight horizontal line, then the R-squared value becomes negative.  This usually happened when a constant is not included in the model.  Getting a negative value for R-squared means that your model does very poorly in explaining the target.\n",
    "\n",
    "### Comparing Different Models \n",
    "\n",
    "Comparing different models and choosing the best one is one of the essential practices in data science.  Often, several models are tried and their performance is evaluated on a test set in order to determine the top performing one.  However, _interference_ is also a critical task when it comes to linear regression models.  Unlike testing the predictive power, in interference, you care about the explanatory power of you models.  \n",
    "\n",
    "Through out this notebook, you saw that you can measure the performance of you models on the training set using F-test or R-squared.  Hence, both F-test and R-squared can be used in the comparison of differing models.  Unfortunately, the two metrics suffer from some drawbacks that make them inappropriate to use in certain situations.\n",
    "\n",
    "### Using F-tests for Model Comparison \n",
    "\n",
    "You can use an F-test to compare tow models if one of them is nested within the other.  That is, if the feature set in a model is a subset of the feature set of the other, then you can use F-test.  In this case you say that the model with the higher F statistic is superior to the other one.\n",
    "\n",
    "However, if models are not nested, then using an F-test may be misleading.  F-tests are quite sensitive to the normality of the error terms.  If errors are not normally distributed, you should try other methods.\n",
    "\n",
    "### Using R-squared for Model comparison\n",
    "\n",
    "R-squared can also be used.  You already saw that R-squared is biased as it tends to increase with the number of explanatory variables.  So, instead of R-squared, you can use adjusted R-squared.  Thei higher adjusted R-squared, the better the model explains the target variable.\n",
    "\n",
    "### Using Information Criteria\n",
    "\n",
    "Using information criteria is also a common way of comparing different models and selecting the best one.  Two information criteria known as the **Akaike Information Criterion (AIC)** and **Bayesian Information Criterion (BIC)** take into consideration the sum of the squared errors (SSE), the sample size, and the number of parameters.\n",
    "\n",
    "The formula for AIC is:\n",
    "$$nln(SSE)−nln(n)+2p$$ \n",
    "The formula for BIC is:\n",
    "$$nln(SSE)−nln(n)+pln(n)$$\n",
    "\n",
    "In both of these formulas, $n$ represents the sample size, and $p$ represents the number of regression coefficients in the model (including the constant).  $ln$ stands for the natural logarithm.  \n",
    "\n",
    "For both AIC and BIC, the lower the value the better.  Hence, you choose the model with the lowest AIC or BIC value.  Although you can use either of the two criteria, AIC is usually criticized for its tendency to overfit.  In contrast, BIC penalizes the number of parameters more severely then AIC and hence favors mor parsimonious models (that is models with fewer parameters).\n",
    "\n",
    "### Which Medical Costs Model is Better?\n",
    "\n",
    "`'statsmodels'` `summary()` function give you all of the above metrics.  In the tables above you see that for your first model R-squared is $0.747$, adjusted R-squared is $0.747$, F statistic is $986.5$, AIC is $27.120$ and BIC is $27.150$.  For the second model, R-squared is $0.837$, adjusted R-squared is $0.836$, F statistic is $1365$, AIC is $26.540$ and BIC is $26.570$.  According to all of the metrics, the second model seems better than the first one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "As in previous checkpoints, please submit links to two Juypyter notebooks (one for each assignment below).\n",
    "\n",
    "Please submit links to all your work below. This is not a graded checkpoint, but you should discuss your solutions with your mentor. Also, when you're done, compare your work to [these example solutions](https://github.com/Thinkful-Ed/machine-learning-regression-problems/blob/master/notebooks/5.solution_evaluating_goodness_of_fit.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "### 1. Weather model\n",
    "\n",
    "For this assignment, you'll revisit the historical temperature dataset. To complete this assignment, submit a link a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* First, load the dataset from the **weatherinszeged** table from Thinkful's database.\n",
    "* Like in the previous checkpoint, build a linear regression model where your target variable is the difference between the *apparenttemperature* and the *temperature*. As explanatory variables, use *humidity* and *windspeed*. Now, estimate your model using OLS. What are the R-squared and adjusted R-squared values? Do you think they are satisfactory? Why? \n",
    "* Next, include the interaction of *humidity* and *windspeed* to the model above and estimate the model using OLS. Now, what is the R-squared of this model? Does this model improve upon the previous one? \n",
    "* Add *visibility* as an additional explanatory variable to the first model and estimate it. Did R-squared increase? What about adjusted R-squared? Compare the differences put on the table by the interaction term and the *visibility* in terms of the improvement in the adjusted R-squared. Which one is more useful?\n",
    "* Choose the best one from the three models above with respect to their AIC and BIC scores. Validate your choice by discussing your justification with your mentor.\n",
    "\n",
    "\n",
    "###  2. House prices model\n",
    "\n",
    "In this exercise, you'll work on your house prices model. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Run your house prices model again and assess the goodness of fit of your model using F-test, R-squared, adjusted R-squared, AIC and BIC.\n",
    "* Do you think your model is satisfactory? If so, why?\n",
    "* In order to improve the goodness of fit of your model, try different model specifications by adding or removing some variables. \n",
    "* For each model you try, get the goodness of fit metrics and compare your models with each other. Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
